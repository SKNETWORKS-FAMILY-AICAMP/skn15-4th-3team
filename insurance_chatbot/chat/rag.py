# chat/rag.py
import os
from operator import itemgetter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_postgres import PGVector

from dotenv import load_dotenv

load_dotenv()

# --- í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PG_CONN = os.getenv("PG_CONN")

# --- LLM & Embeddings ---
llm = ChatOpenAI(model="gpt-4o-mini", api_key=OPENAI_API_KEY)
embed = OpenAIEmbeddings(api_key=OPENAI_API_KEY)

# --- Retriever ì„¸íŒ… ---
def get_retriever():
    vs = PGVector(
        embeddings=embed,
        collection_name="insurance_all",  # ì‹¤ì œ collection ì´ë¦„ìœ¼ë¡œ êµì²´
        connection=PG_CONN,
        use_jsonb=True,
    )
    return vs.as_retriever(
        search_type="mmr",
        search_kwargs={"k": 4, "fetch_k": 20, "lambda_mult": 0.8},
    )

retriever = get_retriever()  # ëª¨ë“ˆ ë¡œë”© ì‹œ í•œ ë²ˆë§Œ

# --- Prompt ---
prompt = ChatPromptTemplate.from_template(
    """
    ë‹¹ì‹ ì€ ìš´ì „ì ë³´í—˜ì„ ì „ë¬¸ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.  
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ ì§€ì¹¨ì„ ê¼­ ì§€ì¼œ ë‹µë³€í•˜ì„¸ìš”.

    [ì§ˆë¬¸]: {question}
    [ì»¨í…ìŠ¤íŠ¸]: {context}
    [ì²¨ë¶€ íŒŒì¼ ë‚´ìš©]: {file_content}

    ì§€ì‹œì‚¬í•­:
    - í•œêµ­ì–´ë¡œ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.  
    - ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ì€ ì¤„ì´ê³ , í•µì‹¬ ì •ë³´ ìœ„ì£¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.  
    - **ì£¼ìš” ë³´ì¥ í•­ëª©ê³¼ ì°¨ì´ì **ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.  
    - ì—¬ëŸ¬ íšŒì‚¬ë¥¼ ë¹„êµí•  ë•ŒëŠ” ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  
    - í‘œì—ëŠ” 'ì¶”ì²œë„' ì—´ì„ ì¶”ê°€í•˜ê³ , â—¯ / â–³ / âœ• / â€” ê¸°í˜¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  
    - ì¶”ì²œë„ ì‚¬ìš© ì‹œ, í‘œ ë°”ë¡œ ì•„ë˜ì¤„ì— ë²”ë¡€ë¥¼ ë°˜ë“œì‹œ ì¶”ê°€í•˜ì‹œì˜¤: â—¯ ì¶”ì²œ / â–³ ë³´í†µ / âœ• ì—†ìŒ / â€” ë¯¸í™•ì¸
    - ë‹µë³€ ë§ˆì§€ë§‰ì—ëŠ” ì‚¬ìš©ìê°€ ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.  
    - ë°˜ë“œì‹œ ì‚¬ìš©í•œ ì •ë³´ì˜ ì¶œì²˜ë¥¼ (ì¶œì²˜: íŒŒì¼ëª…, p.í˜ì´ì§€) í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    - íŒŒì¼ì´ ì²¨ë¶€ëœ ê²½ìš° ì²¨ë¶€ëœ íŒŒì¼ì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ëŒ€ë‹µí•©ë‹ˆë‹¤.
    """
)


# --- ë¬¸ì„œ í¬ë§· í•¨ìˆ˜ ---
def format_docs(docs):
    lines = []
    for d in docs:
        src = d.metadata.get("source", "")
        page = d.metadata.get("page", "?")
        lines.append(f"{d.page_content}\n(ì¶œì²˜: {os.path.basename(src)}, p.{page})")
    return "---".join(lines)


# --- ìµœì¢… RAG ì‹¤í–‰ í•¨ìˆ˜ ---
def rag_answer(question: str, file_path: str = None) -> str:
    """
    íŒŒì¼ ë‚´ìš©ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” RAG í•¨ìˆ˜
    """
    # ğŸ› í•´ê²°: file_contentë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ë¨¼ì € ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    file_content = ''
    
    # íŒŒì¼ì´ ì¡´ì¬í•  ê²½ìš°ì—ë§Œ ë‚´ìš©ì„ ì½ì–´ì˜µë‹ˆë‹¤.
    if file_path and os.path.exists(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                file_content = f.read()
        except Exception as e:
            print(f"Error reading file {file_path}: {e}")
            # íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ì‹œì—ë„ ê³„ì† ì§„í–‰í•˜ë„ë¡ file_contentëŠ” ''ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.

    # 1. ê²€ìƒ‰ (Retrieve)
    docs = retriever.get_relevant_documents(question)
    context = format_docs(docs)
    
    # 2. í”„ë¡¬í”„íŠ¸ ìƒì„± (Prompt)
    chat_input = prompt.format(
        question=question, 
        context=context, 
        file_content=file_content
    )
    
    # 3. LLM í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„± (Generate)
    answer = llm.invoke(chat_input)
    
    return answer.content.strip()
